# Awesome-Unified-Multimodal

All the papers listed in this project come from my usual reading.
If you have found some new and interesting papers, I would appreciate it if you let me know! You can contact me via my email address: niuyuwei04@gmail.com

+ [2023-08-12] SEED: Planting a SEED of Vision in Large Language Model
  [![Static Badge](https://img.shields.io/badge/2307.08041-red?logo=arxiv)](https://arxiv.org/abs/2307.08041) [![Static Badge](https://img.shields.io/badge/SEED-black?logo=github)](https://github.com/AILab-CVC/SEED)

+ [2024-03-22] LaVIT: Unified Language-Vision Pretraining in LLM with Dynamic Discrete Visual Tokenization
  [![Static Badge](https://img.shields.io/badge/2309.04669-red?logo=arxiv)](https://arxiv.org/abs/2309.04669) [![Static Badge](https://img.shields.io/badge/LaVIT-black?logo=github)](https://github.com/jy0205/LaVIT)

+ [2024-04-22] SEED-X: Multimodal Models with Unified Multi-granularity Comprehension and Generation
  [![Static Badge](https://img.shields.io/badge/2404.14396-red?logo=arxiv)](https://arxiv.org/abs/2404.14396) [![Static Badge](https://img.shields.io/badge/SEED-X-black?logo=github)](https://github.com/AILab-CVC/SEED-X)

+ [2024-05-08] Emu: Generative Pretraining in Multimodality
  [![Static Badge](https://img.shields.io/badge/2307.05222-red?logo=arxiv)](https://arxiv.org/abs/2307.05222) [![Static Badge](https://img.shields.io/badge/Emu-black?logo=github)](https://github.com/baaivision/Emu)

+ [2024-05-08] Emu2: Generative Multimodal Models are In-Context Learners
  [![Static Badge](https://img.shields.io/badge/2312.13286-red?logo=arxiv)](https://arxiv.org/abs/2312.13286) [![Static Badge](https://img.shields.io/badge/Emu2-black?logo=github)](https://github.com/baaivision/Emu2)

+ [2024-05-16] Chameleon: Mixed-Modal Early-Fusion Foundation Models
  [![Static Badge](https://img.shields.io/badge/2405.09818-red?logo=arxiv)](https://arxiv.org/abs/2405.09818) [![Static Badge](https://img.shields.io/badge/Chameleon-black?logo=github)](https://github.com/facebookresearch/chameleon)

+ [2024-08-20] Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model
  [![Static Badge](https://img.shields.io/badge/2408.11039-red?logo=arxiv)](https://arxiv.org/abs/2408.11039) [![Static Badge](https://img.shields.io/badge/Transfusion-lucidrains-black?logo=github)](https://github.com/lucidrains/transfusion-pytorch)

+ [2024-09-27] Emu3: Next-Token Prediction is All You Need
  [![Static Badge](https://img.shields.io/badge/2409.18869-red?logo=arxiv)](https://arxiv.org/abs/2409.18869) [![Static Badge](https://img.shields.io/badge/Emu3-black?logo=github)](https://github.com/baaivision/Emu3)

+ [2024-10-15] MMAR: Towards Lossless Multi-Modal Auto-Regressive Probabilistic Modeling
  [![Static Badge](https://img.shields.io/badge/2410.10798-red?logo=arxiv)](https://arxiv.org/abs/2410.10798) [![Static Badge](https://img.shields.io/badge/MMAR-black?logo=github)](https://github.com/ydcUstc/MMAR)

+ [2024-10-17] Janus: Decoupling Visual Encoding for Unified Multimodal Understanding and Generation
  [![Static Badge](https://img.shields.io/badge/2410.13848-red?logo=arxiv)](https://arxiv.org/abs/2410.13848) [![Static Badge](https://img.shields.io/badge/Janus-black?logo=github)](https://github.com/deepseek-ai/Janus)

+ [2024-10-21] PUMA: Empowering Unified MLLM with Multi-granular Visual Generation
  [![Static Badge](https://img.shields.io/badge/2410.13861-red?logo=arxiv)](https://arxiv.org/abs/2410.13861) [![Static Badge](https://img.shields.io/badge/PUMA-black?logo=github)](https://github.com/rongyaofang/PUMA)

+ [2024-10-21] Show-o: One Single Transformer to Unify Multimodal Understanding and Generation
  [![Static Badge](https://img.shields.io/badge/2408.12528-red?logo=arxiv)](https://arxiv.org/abs/2408.12528) [![Static Badge](https://img.shields.io/badge/Show-o-black?logo=github)](https://github.com/showlab/Show-o)

+ [2024-10-23] VILA-U: A Unified Foundation Model Integrating Visual Understanding and Generation
  [![Static Badge](https://img.shields.io/badge/2409.04429-red?logo=arxiv)](https://arxiv.org/abs/2409.04429) [![Static Badge](https://img.shields.io/badge/VILA-U-black?logo=github)](https://github.com/mit-han-lab/vila-u)

+ [2024-10-31] MIO: A Foundation Model on Multimodal Tokens
  [![Static Badge](https://img.shields.io/badge/2409.17692-red?logo=arxiv)](https://arxiv.org/abs/2409.17692) [![Static Badge](https://img.shields.io/badge/MIO-black?logo=github)](https://github.com/MIO-Team/MIO)

+ [2024-11-12] JanusFlow: Harmonizing Autoregression and Rectified Flow for Unified Multimodal Understanding and Generation
  [![Static Badge](https://img.shields.io/badge/2411.07975-red?logo=arxiv)](https://arxiv.org/abs/2411.07975) [![Static Badge](https://img.shields.io/badge/JanusFlow-black?logo=github)](https://github.com/deepseek-ai/Janus)

+ [2024-11-28] Orthus: Autoregressive Interleaved Image-Text Generation with Modality-Specific Heads
    [![Static Badge](https://img.shields.io/badge/2412.00127-red?logo=arxiv)](https://arxiv.org/abs/2412.00127)


+ [2024-12-04] TokenFlow: Unified Image Tokenizer for Multimodal Understanding and Generation
  [![Static Badge](https://img.shields.io/badge/2412.03069-red?logo=arxiv)](https://arxiv.org/abs/2412.03069) [![Static Badge](https://img.shields.io/badge/TokenFlow-black?logo=github)](https://github.com/ByteFlow-AI/TokenFlow)

+ [2024-12-05] Liquid: Language Models are Scalable Multi-modal Generators
  [![Static Badge](https://img.shields.io/badge/2412.04332-red?logo=arxiv)](https://arxiv.org/abs/2412.04332)

+ [2024-12-05] MUSE-VL: Modeling Unified VLM through Semantic Discrete Encoding
  [![Static Badge](https://img.shields.io/badge/2411.17762-red?logo=arxiv)](https://arxiv.org/abs/2411.17762)

+ [2024-12-09] ILLUME: Illuminating Your LLMs to See, Draw, and Self-Enhance
  [![Static Badge](https://img.shields.io/badge/2412.06673-red?logo=arxiv)](https://arxiv.org/abs/2412.06673)

+ [2024-12-09] Visual Lexicon: Rich Image Features in Language Space
  [![Static Badge](https://img.shields.io/badge/2412.06774-red?logo=arxiv)](https://arxiv.org/abs/2412.06774)

+ [2024-12-11] Multimodal Latent Language Modeling with Next-Token Diffusion
  [![Static Badge](https://img.shields.io/badge/2412.08635-red?logo=arxiv)](https://arxiv.org/abs/2412.08635)




# Useful Links

+ [Awesome-Unified-Multimodal-Models](https://github.com/showlab/Awesome-Unified-Multimodal-Models)
